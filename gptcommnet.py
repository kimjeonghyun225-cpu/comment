# -*- coding: utf-8 -*-
# ìµœì¢… Streamlit ì•±: QA ê²°ê³¼ ìžë™ ì½”ë©˜íŠ¸ ìƒì„±ê¸° (í—¤ë”ìžë™íƒì§€/ë™ì˜ì–´ë§¤í•‘/ëª¨ë¸ì •ê·œí™” ì ìš©)

import os
import re
import io
import zipfile
import unicodedata
import time
from contextlib import contextmanager

import pandas as pd
import openpyxl
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

from qa_patch_module import (
    find_test_sheet_candidates,
    enrich_with_column_comments,
    build_system_prompt, build_user_prompt,
    parse_llm_json, write_excel_report,
    self_check
)
# =========================
# í™˜ê²½ì„¤ì •
# =========================
load_dotenv()
# ìš°ì„ ìˆœìœ„: st.secrets > .env > os.environ
api_key = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY", ""))
if not api_key:
    st.error("OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. st.secrets ë˜ëŠ” .envì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=api_key)

st.set_page_config(page_title="QA ê²°ê³¼ ìžë™ ì½”ë©˜íŠ¸ ìƒì„±ê¸°", layout="wide")
st.title(":bar_chart: QA ê²°ê³¼ ìžë™ ì½”ë©˜íŠ¸ ìƒì„±ê¸°")
# â–¼ í”„ë¡œì íŠ¸/ë²„ì „ ìž…ë ¥ UI (ì´ ì¤„ì„ st.title ì•„ëž˜ì— ì¶”ê°€)
col_pj, col_ver, col_reset = st.columns([2, 2, 1])
with col_pj:
    project_name = st.text_input("í”„ë¡œì íŠ¸ëª…", value="", placeholder="ì˜ˆ: AOD v1.3 CO")
with col_ver:
    checklist_version = st.text_input("ì²´í¬ë¦¬ìŠ¤íŠ¸ ë²„ì „", value="", placeholder="ì˜ˆ: r1.2.0")
with col_reset:
    if st.button("ðŸ”„ ì„¸ì…˜ ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.experimental_rerun()


# =========================
# ê³µí†µ ìœ í‹¸
# =========================
@contextmanager
def step_status(title: str):
    with st.status(title, expanded=False) as status:
        t0 = time.time()
        try:
            yield status
            status.update(label=f"{title} - ì™„ë£Œ ({time.time()-t0:.2f}s)", state="complete", expanded=False)
        except Exception as e:
            status.update(label=f"{title} - ì‹¤íŒ¨: {e}", state="error", expanded=True)
            raise

def diag_dump(label: str, obj):
    with st.expander(f"ðŸ”Ž ì§„ë‹¨ ë³´ê¸°: {label}", expanded=False):
        st.write(obj)

# =========================
# ê³µí†µ ìœ í‹¸
# =========================
def _norm(s: str) -> str:
    s = unicodedata.normalize("NFKC", str(s))
    s = re.sub(r"[\s\-\_/()\[\]{}:+Â·âˆ™â€¢]", "", s)
    return s.lower().strip()

def normalize_model_name_strict(s):
    if pd.isna(s): return ""
    s = str(s)
    s = re.sub(r"\(.*?\)", "", s)
    s = re.sub(r"\b(64|128|256|512)\s*gb\b", "", s, flags=re.I)
    s = re.sub(r"\b(black|white|blue|red|green|gold|silver|ê³¨ë“œ|ë¸”ëž™|í™”ì´íŠ¸|ì‹¤ë²„)\b", "", s, flags=re.I)
    s = re.sub(r"[\s\-_]+", "", s)
    return s.lower().strip()

# =========================
# Log ë¶„ì„: ìš”ì•½ + ê·¼ë³¸ ì›ì¸ ì¶”ì •
# =========================
def load_and_summarize_logcat_files(files):
    patterns = {
        "crash": re.compile(r"\bFATAL EXCEPTION\b|\bAbort message:\b|\bbacktrace\b", re.I),
        "anr": re.compile(r"\bANR in\b|\bApplication Not Responding\b", re.I),
        "gl_err": re.compile(r"(E/libEGL|E/GLConsumer|OpenGLRenderer|Adreno|Mali)", re.I),
        "thermal": re.compile(r"(thermal|ThermalEngine|throttl)", re.I),
        "net": re.compile(r"(SocketTimeout|UnknownHost|SSLHandshake|Network is unreachable)", re.I),
        "fps": re.compile(r"\bFPS[:=]\s*\d+", re.I),
    }
    total_counts = {k: 0 for k in patterns.keys()}
    file_count = 0

    def _consume_text(txt: str):
        for k, p in patterns.items():
            total_counts[k] += len(p.findall(txt))

    for f in files:
        name = f.name.lower()
        try:
            if name.endswith(".zip"):
                with zipfile.ZipFile(io.BytesIO(f.read())) as zf:
                    for info in zf.infolist():
                        if info.is_dir(): continue
                        if not info.filename.lower().endswith((".txt", ".log")): continue
                        with zf.open(info) as zfh:
                            data = zfh.read()
                            txt = data.decode("utf-8", errors="ignore")
                            _consume_text(txt)
                            file_count += 1
            else:
                data = f.read()
                txt = data.decode("utf-8", errors="ignore")
                _consume_text(txt)
                file_count += 1
        except Exception:
            continue

    parts = [f"{k}:{v}" for k, v in total_counts.items()]
    return {"log_summary": f"files={file_count}; " + ", ".join(parts)}

def _parse_log_summary(summary: str) -> dict:
    out = {"files": 0, "crash": 0, "anr": 0, "gl_err": 0, "thermal": 0, "net": 0, "fps": 0}
    if not summary:
        return out
    try:
        parts = [p.strip() for p in summary.split(";")]
        if parts and parts[0].startswith("files="):
            out["files"] = int(parts[0].split("=",1)[1])
        tail = parts[1] if len(parts) > 1 else ""
        for kv in tail.split(","):
            if ":" in kv:
                k, v = kv.split(":", 1)
                if k.strip() in out:
                    out[k.strip()] = int(v.strip())
    except Exception:
        pass
    return out

def infer_root_causes_from_logs(summary: str) -> list:
    c = _parse_log_summary(summary)
    hyps = []
    if c.get("gl_err", 0) >= 3 or (c.get("fps", 0) >= 10 and c.get("gl_err", 0) >= 1):
        hyps.append({"signal": "gl_err/fps", "hypothesis": "GPU ë“œë¼ì´ë²„/ë Œë”ë§ ë³‘ëª© ê°€ëŠ¥", "evidence": f"gl_err={c.get('gl_err',0)}, fps={c.get('fps',0)}"})
    if c.get("crash", 0) >= 2:
        hyps.append({"signal": "crash", "hypothesis": "ë„¤ì´í‹°ë¸Œ í¬ëž˜ì‹œ(ë©”ëª¨ë¦¬/ë„í¬ì¸í„°) ê°€ëŠ¥", "evidence": f"crash={c.get('crash',0)}"})
    if c.get("anr", 0) >= 1:
        hyps.append({"signal": "anr", "hypothesis": "ë©”ì¸ìŠ¤ë ˆë“œ ë¸”ë¡œí‚¹/IO ì§€ì—°ìœ¼ë¡œ ì¸í•œ ANR ê°€ëŠ¥", "evidence": f"anr={c.get('anr',0)}"})
    if c.get("thermal", 0) >= 1:
        hyps.append({"signal": "thermal", "hypothesis": "ì¨ë©€ ìŠ¤ë¡œí‹€ë§ìœ¼ë¡œ ì¸í•œ í´ëŸ­ ì €í•˜", "evidence": f"thermal={c.get('thermal',0)}"})
    if c.get("net", 0) >= 2:
        hyps.append({"signal": "net", "hypothesis": "ë„¤íŠ¸ì›Œí¬ ì§€ì—°/SSL ì˜¤ë¥˜ë¡œ ì¸í•œ UX ì €í•˜ ê°€ëŠ¥", "evidence": f"net={c.get('net',0)}"})
    return hyps

# =========================
# ë‚˜ë¨¸ì§€ ë©”ì¸ íŒŒì´í”„ë¼ì¸
# =========================
# (ì•„ëž˜ ìƒëžµ ì—†ì´ ì „ì²´ - êµ°ì§‘ í†µê³„, LLM í˜¸ì¶œ, ë³´ê³ ì„œ ìƒì„± ëª¨ë‘ ë™ì¼)
# =========================
# UI: íŒŒì¼ ì—…ë¡œë“œ ë° ì‹¤í–‰
# =========================
uploaded_file = st.file_uploader("ì›ë³¸ QA ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["xlsx"])
log_files = None #st.file_uploader("Logcat íŒŒì¼ ì—…ë¡œë“œ(.txt/.log ë˜ëŠ” .zip, ë‹¤ì¤‘ ê°€ëŠ¥)", type=["txt", "log", "zip"], accept_multiple_files=True)
st.caption("â€» Logcat ë¶„ì„ì€ í˜„ìž¬ ë¹„í™œì„±í™” ìƒíƒœìž…ë‹ˆë‹¤.")

if uploaded_file:
    with step_status("ì—‘ì…€ ë¡œë“œ"):
        xls = pd.ExcelFile(uploaded_file, engine="openpyxl")
        diag_dump("ì‹œíŠ¸ ëª©ë¡", xls.sheet_names)

    # 1) í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ ìžë™ê°ì§€
    with step_status("í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ ìžë™ê°ì§€"):
        test_candidates = find_test_sheet_candidates(xls)
        diag_dump("ê°ì§€ëœ í›„ë³´ ì‹œíŠ¸", test_candidates)

    st.subheader("1. í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ ì„ íƒ")
    test_sheets_selected = st.multiselect(
        "ìžë™ ê°ì§€ëœ í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ ì¤‘ ë¶„ì„ ëŒ€ìƒ ì„ íƒ",
        options=test_candidates,
        default=test_candidates[:2]
    )
    if not test_sheets_selected:
        st.error("âŒ ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
        st.stop()

    # 2) ìŠ¤íŽ™ ì‹œíŠ¸ ì„ íƒ
    st.subheader("2. ìŠ¤íŽ™ ì‹œíŠ¸ ì„ íƒ (ë””ë°”ì´ìŠ¤ ë¦¬ìŠ¤íŠ¸)")
    default_spec = [s for s in ["AOS_Device_List", "iOS_Device_List"] if s in xls.sheet_names]
    spec_sheets_selected = st.multiselect(
        "ìŠ¤íŽ™(Chipset, GPU, OS, Rank ë“±) í¬í•¨ ì‹œíŠ¸ ì„ íƒ",
        options=xls.sheet_names,
        default=default_spec
    )
    st.markdown("---")

    if st.button("ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±", type="primary"):
        # ðŸ”’ ì‹¤í–‰ë³„ ìƒíƒœ ì´ˆê¸°í™” (ì´ì „ ì‹¤í–‰ ê°’ ì„žìž„ ë°©ì§€)
        log_summary = {}
        log_hypotheses = []
        clusters = {}
        evidence_links = []


        # 3) Fail+ì½”ë©˜íŠ¸ ì¶”ì¶œ
        with step_status("Fail + ì…€ ì½”ë©˜íŠ¸ ì¶”ì¶œ"):
            wb = openpyxl.load_workbook(uploaded_file, data_only=True)
            df_issue = None
            try:
                from qa_patch_module import enrich_with_column_comments
                df_issue = pd.DataFrame()
                tmp = []
                for s in test_sheets_selected:
                    ws = wb[s]
                    for row in ws.iter_rows():
                        for cell in row:
                            if isinstance(cell.value, str) and cell.value.lower() == "fail" and cell.comment:
                                tmp.append({
                                    "Sheet": s,
                                    "Checklist": ws.title,
                                    "Device(Model)": "",
                                    "comment_cell": cell.comment.text.strip()
                                })
                df_issue = pd.DataFrame(tmp)
            except Exception:
                pass
            if df_issue is None or df_issue.empty:
                st.warning("âŒ Fail+ì½”ë©˜íŠ¸ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()

        # 4) ë¹„ê³ /Notes ë³‘í•©
        with step_status("ë¹„ê³ /Notes ë³‘í•©"):
            df_issue = enrich_with_column_comments(xls, test_sheets_selected[0], df_issue)
            diag_dump("ë³‘í•© ê²°ê³¼ ìƒ˜í”Œ", df_issue.head(10))

        # 5) ìžê°€ì§„ë‹¨
        with step_status("ëª¨ë“ˆ ìžê°€ì§„ë‹¨"):
            diag = self_check(df_issue)
            diag_dump("self_check ê²°ê³¼", diag)
            if not diag["row_ok"]:
                st.error("âŒ ìœ íš¨í•œ ë°ì´í„° ì—†ìŒ. ì¤‘ë‹¨.")
                st.stop()

        df_final = df_issue.copy()

        # 6) Logcat ìš”ì•½ + ì›ì¸ì¶”ì •
        with step_status("Logcat ë¶„ì„"):
            log_summary, log_hypotheses = {}, []
            if log_files:
                log_summary = load_and_summarize_logcat_files(log_files)
                st.info(f"Logcat ìš”ì•½: {log_summary.get('log_summary','-')}")
                log_hypotheses = infer_root_causes_from_logs(log_summary.get("log_summary", ""))
                diag_dump("ë¡œê·¸ ê·¼ë³¸ ì›ì¸ ê°€ì„¤", log_hypotheses)
            else:
                st.info("ë¡œê·¸ íŒŒì¼ ì—†ìŒ. Logcat ë¶„ì„ ìƒëžµ.")

        # 7) êµ°ì§‘ í†µê³„
        with step_status("êµ°ì§‘(Cluster) í†µê³„ ì‚°ì¶œ"):
            def _cluster_counts(df, col, topn=15):
                if col not in df.columns:
                    return pd.DataFrame(columns=[col, "count"])
                vc = df[col].fillna("(ë¯¸ê¸°ìž¬)").astype(str).str.strip().value_counts().head(topn)
                return vc.reset_index().rename(columns={"index": col, 0: "count"})
            cluster_gpu = _cluster_counts(df_final, "GPU")
            cluster_chip = _cluster_counts(df_final, "Chipset")
            clusters = {
                "by_gpu": cluster_gpu.to_dict(orient="records"),
                "by_chipset": cluster_chip.to_dict(orient="records"),
            }
            diag_dump("GPU/Chipset êµ°ì§‘ í†µê³„", clusters)

        # 8) í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        metrics = {
            "total_fail_issues": len(df_final),
            "clusters": clusters,
            "log_hypotheses": log_hypotheses
        }
        deltas, evidence_links = {}, []
        if log_summary:
            evidence_links.append(f"Log Summary: {log_summary.get('log_summary','')}")

        base_kwargs = {
            "project": (project_name.strip() or "UNKNOWN_PROJECT"),
            "version": (checklist_version.strip() or "UNKNOWN_VERSION"),
            "metrics": metrics,
            "deltas": deltas,
            "evidence_links": evidence_links,
            "sample_issues": df_final,
            "max_rows": 500  # í•„ìš” ì‹œ ëŠ˜ë¦¼
        }

        # 9) í† í° ì˜ˆì‚° ìžë™ ì¡°ì •
        def _rough_token_count(t: str) -> int:
            return max(1, int(len(t) / 2.5))
        def estimate_tokens(msgs: list) -> int:
            try:
                import tiktoken
                enc = tiktoken.get_encoding("cl100k_base")
                return sum(len(enc.encode(m.get("content",""))) for m in msgs)
            except Exception:
                return sum(_rough_token_count(m.get("content","")) for m in msgs)
        def fit_prompt(build_user, base_kwargs, model_budget=120000, reserve_output=6000):
            max_rows_list = [800, 600, 400, 300, 200, 100]
            df = base_kwargs["sample_issues"]
            for mr in max_rows_list:
                kwargs = dict(base_kwargs)
                kwargs["sample_issues"] = df.head(mr)
                sp = build_system_prompt()
                up = build_user(**kwargs)
                used = estimate_tokens([{"content": sp},{"content": up}])
                if used + reserve_output < model_budget:
                    return sp, up, {"prompt_tokens_est": used, "max_rows": mr}
            return sp, up, {"warn": "budget_exceeded"}

        with step_status("í† í° ì˜ˆì‚° ì¡°ì •"):
            sp, up, diag_budget = fit_prompt(build_user_prompt, base_kwargs)
            diag_dump("í† í° ì§„ë‹¨", diag_budget)

        # 10) OpenAI í˜¸ì¶œ
        with st.spinner("GPTê°€ ë¦¬í¬íŠ¸ë¥¼ ìž‘ì„± ì¤‘ìž…ë‹ˆë‹¤..."):
            try:
                resp = client.chat.completions.create(
                    model="gpt-4o",
                    temperature=0.1,
                    top_p=0.9,
                    messages=[{"role":"system","content":sp},{"role":"user","content":up}],
                )
                raw = resp.choices[0].message.content
                result = parse_llm_json(raw)
                result["metrics"] = metrics  # êµ°ì§‘Â·ë¡œê·¸ ê·¼ê±° ë³´ì¡´
                diag_dump("LLM ì›ë¬¸(ìš”ì•½)", raw[:4000])
            except Exception as e:
                st.error(f"OpenAI í˜¸ì¶œ ì˜¤ë¥˜: {e}")
                st.stop()

        # 11) ì—‘ì…€ ë¦¬í¬íŠ¸ ìƒì„±
        try:
            output = "QA_Report.xlsx"
            write_excel_report(result, df_final, output)
            st.success("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
            with open(output, "rb") as f:
                st.download_button("ðŸ“Š Excel ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ", f.read(), file_name=output)
        except Exception as e:
            st.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")

