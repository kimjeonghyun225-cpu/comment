# -*- coding: utf-8 -*-
# Streamlit ì•±: QA ê²°ê³¼ ìë™ ì½”ë©˜íŠ¸ ìƒì„±ê¸° (ìµœì¢…)

import os, re, io, time, unicodedata
from contextlib import contextmanager
from typing import List, Dict, Any, Optional

import pandas as pd
import openpyxl
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

from qa_patch_module import (
    find_test_sheet_candidates,
    extract_comments_as_dataframe_dual,
    enrich_with_column_comments,
    self_check,
    parse_llm_json,
    build_system_prompt,
    build_user_prompt,
    write_excel_report,
    load_threaded_comments_map_from_bytes,
)

# ==============================
# í™˜ê²½/ì´ˆê¸° ì„¤ì •
# ==============================
load_dotenv()

st.set_page_config(
    page_title="í˜¸í™˜ì„± QA ìë™ ë¦¬í¬íŠ¸",
    layout="wide",
)

# ì„¸ì…˜ ì´ˆê¸°í™” ë²„íŠ¼: ì´ì „ ì—…ë¡œë“œ/ìƒíƒœë¥¼ ì™„ì „íˆ ë¹„ìš°ê³  ìƒˆë¡œ ì‹œì‘
if st.sidebar.button("ğŸ”„ ì„¸ì…˜ ì´ˆê¸°í™” / ìƒˆ íŒŒì¼ ë¶„ì„"):
    for k in list(st.session_state.keys()):
        del st.session_state[k]
    st.experimental_rerun()

@contextmanager
def step_status(msg: str):
    st.write(f"### â± {msg}")
    with st.spinner(msg + "..."):
        start = time.time()
        try:
            yield
        finally:
            dt = time.time() - start
            st.write(f"âœ… ì™„ë£Œ ({dt:0.1f}s) - {msg}")

def diag_dump(title: str, obj):
    """ë””ë²„ê·¸ìš© ë¤í”„(í•„ìš” ì‹œë§Œ st.write)."""
    with st.expander(f"ğŸ” {title}", expanded=False):
        if isinstance(obj, (pd.DataFrame, pd.Series)):
            st.dataframe(obj)
        else:
            st.write(obj)

# ==============================
# OpenAI í´ë¼ì´ì–¸íŠ¸
# ==============================
api_key = os.getenv("OPENAI_API_KEY", "").strip()
if not api_key:
    st.error("âŒ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. st.secrets ë˜ëŠ” .envì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=api_key)

# ==============================
# UI: íŒŒì¼ ì—…ë¡œë“œ
# ==============================
st.title("í˜¸í™˜ì„± QA ìë™ ë¦¬í¬íŠ¸ ìƒì„±ê¸°")

uploaded = st.file_uploader("ex) KP 4.2.0 Build CO QA Report_In.xlsx íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["xlsx"])
if not uploaded:
    st.stop()

data = uploaded.read()
xls = io.BytesIO(data)

# ==============================
# 1) í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ ìë™ íƒì§€
# ==============================
with step_status("í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ ìë™ íƒì§€"):
    try:
        wb = openpyxl.load_workbook(xls, data_only=True)
        sheet_names = wb.sheetnames
        st.write("ğŸ“„ ê°ì§€ëœ ì‹œíŠ¸:", ", ".join(sheet_names))
    except Exception as e:
        st.error(f"ì—‘ì…€ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        st.stop()

    test_candidates = find_test_sheet_candidates(sheet_names)
    st.write("ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ í›„ë³´:", ", ".join(test_candidates) if test_candidates else "(ì—†ìŒ)")

    test_sheets_selected = st.multiselect(
        "í…ŒìŠ¤íŠ¸ ê²°ê³¼(Compatibility Test ë“±)ê°€ í¬í•¨ëœ ì‹œíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.",
        options=sheet_names,
        default=test_candidates or sheet_names,
    )
    if not test_sheets_selected:
        st.error("í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ë¥¼ ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
        st.stop()

# ==============================
# 2) ìŠ¤í™ ì‹œíŠ¸(ë””ë°”ì´ìŠ¤ ë¦¬ìŠ¤íŠ¸) ì„ íƒ
# ==============================
with step_status("ìŠ¤í™(ë””ë°”ì´ìŠ¤ ë¦¬ìŠ¤íŠ¸) ì‹œíŠ¸ í›„ë³´ íƒì§€"):
    spec_candidates = []
    for s in sheet_names:
        s_norm = s.lower()
        if any(k in s_norm for k in ["device", "ë‹¨ë§", "list", "spec"]):
            spec_candidates.append(s)
    st.write("ğŸ“± ë‹¨ë§ ìŠ¤í™ ì‹œíŠ¸ í›„ë³´:", ", ".join(spec_candidates) if spec_candidates else "(ì—†ìŒ)")

    spec_sheets_selected = st.multiselect(
        "Device List / Spec ì‹œíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (ì—†ìœ¼ë©´ ìƒëµ ê°€ëŠ¥).",
        options=sheet_names,
        default=spec_candidates,
    )

# ==============================
# 3) í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ì—ì„œ Fail + ì½”ë©˜íŠ¸ ì¶”ì¶œ
# ==============================
with step_status("í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ì—ì„œ Fail + ì½”ë©˜íŠ¸ ì¶”ì¶œ"):
    try:
        wb_comm = openpyxl.load_workbook(io.BytesIO(data), data_only=False)
        wb_val  = openpyxl.load_workbook(io.BytesIO(data), data_only=True)

        available = set(wb_comm.sheetnames) & set(wb_val.sheetnames)
        valid_sheets = [s for s in test_sheets_selected if s in available]
        if not valid_sheets:
            st.error(f"ì„ íƒí•œ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {sorted(list(available))}")
            st.stop()

        # ìŠ¤ë ˆë“œ ëŒ“ê¸€ê¹Œì§€ ì½ì–´ì„œ ë³´ê°•
        threaded_map = load_threaded_comments_map_from_bytes(data)

        df_issue = extract_comments_as_dataframe_dual(
            wb_comm, wb_val, valid_sheets, threaded_map=threaded_map
        )
        # ë””ë²„ê·¸ìš© í™•ì¥ì€ í•„ìš”í•  ë•Œë§Œ ì—´ì–´ë³´ë©´ ë˜ë¯€ë¡œ, í™”ë©´ì—ëŠ” ìµœì¢… ë³‘í•© ë·°(df_final)ë§Œ ë³´ì—¬ì¤€ë‹¤.
        # diag_dump("ì¶”ì¶œëœ Fail+ì½”ë©˜íŠ¸ ì „ì²´", df_issue)

        if df_issue.empty:
            st.warning("âŒ Fail+ì½”ë©˜íŠ¸ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤(ë©”ëª¨/ëŒ“ê¸€ ë¯¸ê²€ì¶œ).")
            st.info("ì—‘ì…€ì—ì„œ í•´ë‹¹ ì…€ì— ì‹¤ì œ ì½”ë©˜íŠ¸ê°€ ì¡´ì¬í•˜ëŠ”ì§€(ìƒˆ ëŒ“ê¸€/ë©”ëª¨), ë³´í˜¸/ìˆ¨ê¹€ ìƒíƒœê°€ ì•„ë‹Œì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
            st.stop()
    except Exception as e:
        st.error(f"ì½”ë©˜íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        st.stop()

# ==============================
# 4) ìŠ¤í™ ë³‘í•© (ëª¨ë¸ëª… ì •ê·œí™” í›„ Joinâ€”í—¤ë” ìë™íƒì§€ + ë¶€ë¶„ì¼ì¹˜ ë°±ì—…)
# ==============================
df_final = df_issue.copy()
match_rate = 0.0

# df_finalì— Device(Model) ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´, ì›ë³¸ í—¤ë” í›„ë³´ì—ì„œ ë³µì‚¬í•´ ìƒì„±
if "Device(Model)" not in df_final.columns:
    for cand in ["Device", "device", "Model", "MODEL", "ë‹¨ë§ëª…", "ëª¨ë¸ëª…"]:
        if cand in df_final.columns:
            df_final["Device(Model)"] = df_final[cand]
            break

df_spec_all = pd.DataFrame()
spec_match_info = None
df_spec_mismatch_sample = pd.DataFrame()

if spec_sheets_selected:
    # â± ìŠ¤í™ ë³‘í•© ë‹¨ê³„ íƒ€ì´í‹€ ì—†ì´ ë‚´ë¶€ì—ì„œë§Œ ë³‘í•© ìˆ˜í–‰
    # ---------- ê³µí†µ ìœ í‹¸ ----------
    def _norm_hdr(s: str) -> str:
        s = unicodedata.normalize("NFKC", str(s))
        s = re.sub(r"[\s\-\_/()\[\]{}:+Â·âˆ™â€¢]", "", s).lower()
        return s

    def find_header_row_for_spec(xls, sheet, max_scan_rows=20):
        """ìŠ¤í™ ì‹œíŠ¸ì—ì„œ í—¤ë” í–‰(ëª¨ë¸ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ í–‰)ì„ ìœ„ì—ì„œë¶€í„° íƒìƒ‰"""
        probe = pd.read_excel(xls, sheet_name=sheet, header=None, engine="openpyxl")
        header_keywords = [r"^model$", r"^device$", r"^ì œí’ˆëª…$", r"^ëª¨ë¸$", r"^ëª¨ë¸ëª…$", r"^ê¸°ì¢…$", r"^ë‹¨ë§$", r"^ë‹¨ë§ëª…$"]
        for i in range(min(max_scan_rows, len(probe))):
            row = probe.iloc[i].astype(str).fillna("")
            hits = 0
            for cell in row:
                c = _norm_hdr(cell)
                if any(re.search(pat, c) for pat in header_keywords):
                    hits += 1
            if hits >= 1:
                return i
        return 0

    def standardize_spec_columns(df: pd.DataFrame) -> pd.DataFrame:
        orig = list(df.columns)
        norm = [_norm_hdr(c) for c in orig]
        col_map = {}
        synonyms = {
            r"^(model|device|ì œí’ˆëª…|ì œí’ˆ|ëª¨ë¸ëª…|ëª¨ë¸|ë‹¨ë§|ë‹¨ë§ëª…|ê¸°ì¢…)$": "Model",
            r"^(maker|manufacturer|brand|oem|ì œì¡°ì‚¬|ë²¤ë”)$": "ì œì¡°ì‚¬",
            r"^(gpu|gpuëª…|gpumodel|graphics|ê·¸ë˜í”½|ê·¸ë˜í”½ì¹©|ê·¸ë˜í”½ìŠ¤|ê·¸ë˜í”½í”„ë¡œì„¸ì„œ)$": "GPU",
            r"^(chipset|soc|ap|cpu|processor)$": "Chipset",
            r"^(ram|ë©”ëª¨ë¦¬)$": "RAM",
            r"^(os|osversion|android|ios|íŒì›¨ì–´|ì†Œí”„íŠ¸ì›¨ì–´ë²„ì „|ìš´ì˜ì²´ì œ|osë²„ì „)$": "OS",
            r"^(rank|rating|ratinggrade|ë“±ê¸‰)$": "Rank",
            # í•´ìƒë„/ë””ìŠ¤í”Œë ˆì´ í•´ìƒë„
            r"^(resolution|í•´ìƒë„|display|displayresolution|resolutiondisplay)$": "Resolution",
        }
        for n, o in zip(norm, orig):
            mapped = None
            for pat, std in synonyms.items():
                if re.search(pat, n):
                    mapped = std
                    break
            col_map[o] = mapped or o
        return df.rename(columns=col_map)

    # ---------- ìŠ¤í™ ì‹œíŠ¸ ì ì¬ ----------
    frames = []
    for sname in spec_sheets_selected:
        try:
            hdr = find_header_row_for_spec(xls, sname)
            dfp = pd.read_excel(xls, sheet_name=sname, header=hdr, engine="openpyxl")
        except Exception:
            continue
        dfp = standardize_spec_columns(dfp)

        # í•„ìˆ˜: Model ì—´
        model_col = "Model" if "Model" in dfp.columns else None
        if not model_col:
            for c in dfp.columns:
                if re.search(r"(model|device|ì œí’ˆëª…|ëª¨ë¸|ê¸°ì¢…|ë‹¨ë§)", _norm_hdr(c)):
                    model_col = c; break
        if not model_col:
            continue

        # ì •ê·œí™” í‚¤ ìƒì„±
        from qa_patch_module import normalize_model_name_strict
        dfp["model_norm"] = dfp[model_col].apply(normalize_model_name_strict)

        # ë³´ì¡° í‚¤(ìƒ‰ìƒÂ·ìš©ëŸ‰ ì œê±° ì „ ì›ë¬¸ë„ ë³´ê´€)
        dfp["model_raw"] = dfp[model_col].astype(str)

        # ìœ ì§€ ì»¬ëŸ¼
        keep = ["model_norm", "model_raw"] + [
            c for c in ["GPU","ì œì¡°ì‚¬","Chipset","RAM","OS","Rank","Model","CPU","Resolution"]
            if c in dfp.columns
        ]
        frames.append(dfp[keep])

    if not frames:
        st.warning("ì„ íƒí•œ ìŠ¤í™ ì‹œíŠ¸ì—ì„œ ìœ íš¨í•œ í—¤ë”/ëª¨ë¸ ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (í—¤ë” ìœ„ì¹˜/ì—´ ì´ë¦„ í™•ì¸)")
    else:
        df_spec_all = pd.concat(frames, ignore_index=True).drop_duplicates("model_norm", keep="first")

        # ---------- ì´ìŠˆìª½ ëª¨ë¸ ì •ê·œí™” ----------
        from qa_patch_module import normalize_model_name_strict
        df_final["model_norm"] = df_final["Device(Model)"].apply(normalize_model_name_strict)

        # 1ì°¨: model_normìœ¼ë¡œ ì •ì„ ë³‘í•©
        df_final = pd.merge(df_final, df_spec_all, on="model_norm", how="left", suffixes=("","_spec"))

        # Chipset ë³´ì •
        if "Chipset" not in df_final.columns and "CPU" in df_final.columns:
            df_final["Chipset"] = df_final["CPU"]

        # ì ‘ë¯¸ì‚¬ ì •ë¦¬
        for col in ["GPU","ì œì¡°ì‚¬","Chipset","RAM","OS","Rank","Model"]:
            cx, cy = f"{col}", f"{col}_spec"
            if cx in df_final.columns and cy in df_final.columns:
                df_final[col] = df_final[cx].where(df_final[cx].notna() & (df_final[cx]!=""), df_final[cy])
                df_final.drop(columns=[cy], inplace=True, errors="ignore")
            elif cy in df_final.columns:
                df_final.rename(columns={cy: col}, inplace=True)

        # ---------- 2ì°¨: ë¶€ë¶„ì¼ì¹˜(contains) ë°±ì—… ë§¤ì¹­ ----------
if "GPU" in df_final.columns:
    mask_need = (
        df_final["GPU"].isna()
        | (df_final["GPU"].astype(str).str.strip() == "")
    ) & (df_final["Device(Model)"].astype(str).str.len() > 0)

    if mask_need.any() and not df_spec_all.empty:
        base_cols = ["model_raw", "GPU", "Chipset", "OS", "Rank"]
        existing_cols = [c for c in base_cols if c in df_spec_all.columns]

        if "model_raw" not in existing_cols:
            st.info("âš  df_spec_allì— model_raw ì»¬ëŸ¼ì´ ì—†ì–´ ë¶€ë¶„ ë§¤ì¹­ì„ ìƒëµí•©ë‹ˆë‹¤.")
        else:
            spec_index = (
                df_spec_all[existing_cols]
                .dropna(subset=["model_raw"])
                .reset_index(drop=True)
            )

            for idx in df_final[mask_need].index.tolist():
                key = str(df_final.at[idx, "Device(Model)"])
                hit = spec_index[spec_index["model_raw"].astype(str).str.contains(key, case=False, na=False)]
                if not hit.empty:
                    h0 = hit.iloc[0].to_dict()
                    for col in ["GPU", "Chipset", "OS", "Rank"]:
                        if col in h0 and pd.isna(df_final.at[idx, col]):
                            df_final.at[idx, col] = h0.get(col, "")

# ìŠ¤í™ ë§¤ì¹­ ìš”ì•½ ì •ë³´(ë‚˜ì¤‘ì— ë³„ë„ UI ì„¹ì…˜ì—ì„œ ì‚¬ìš©)
if "GPU" in df_final.columns:
    matched = int(df_final["GPU"].fillna("").astype(str).str.strip().ne("").sum())
    match_rate = round(matched / max(1, len(df_final)) * 100, 1)
    spec_match_info = {
        "matched": matched,
        "total": int(len(df_final)),
        "match_rate": match_rate,
    }
    df_spec_mismatch_sample = df_final[
        df_final["GPU"].fillna("").astype(str).str.strip() == ""
    ][["Device(Model)", "GPU", "Chipset", "OS", "Rank"]].head(20)

# ==============================
# 6) ìê°€ì§„ë‹¨ (ë‚´ë¶€ ë¡œì§ë§Œ ìˆ˜í–‰, ì›¹ ì¶œë ¥ì€ ìµœì†Œí™”)
# ==============================
diag = self_check(df_final)
if not diag["row_ok"]:
    st.error("âŒ ìœ íš¨í•œ ë°ì´í„° ì—†ìŒ. ì¤‘ë‹¨.")
    st.stop()

# ==============================
# 7) ì½”ë©˜íŠ¸ ì •ê·œí™”/íƒœê¹… (ê³„ì‚°ë§Œ ë¨¼ì € ìˆ˜í–‰)
# ==============================

def _jamo_norm(s: str) -> str:
    if s is None: return ""
    t = unicodedata.normalize("NFKC", str(s))
    t = re.sub(r"[^0-9a-zA-Zê°€-í£\s\-_+/.:]", " ", t)
    t = re.sub(r"\s+", " ", t).strip().lower()
    return t

ISSUE_TAG_PATTERNS = [
    ("punch_hole", r"(í€ì¹˜í™€|punch[\s\-]?hole|hole[-\s]?camera)"),
    ("notch", r"(ë…¸ì¹˜|notch)"),
    ("rotation", r"(íšŒì „|ê°€ë¡œì „í™˜|ì„¸ë¡œì „í™˜|landscape|portrait|rotate)"),
    ("aspect_ratio", r"(í™”ë©´ë¹„|ë¹„ìœ¨|aspect\s?ratio)"),
    ("resolution", r"(í•´ìƒë„|resolution)"),
    ("cutout", r"(ì»·ì•„ì›ƒ|cutout)"),
    ("install", r"(ì„¤ì¹˜\s?ë¶ˆê°€|ì„¤ì¹˜ì˜¤ë¥˜|install\s?fail|íŒ¨í‚¤ì§€\s?ì˜¤ë¥˜|apk\s?ì„¤ì¹˜)"),
    ("permission", r"(ê¶Œí•œ|permission)"),
    ("login", r"(ë¡œê·¸ì¸|login|oauth|ì¸ì¦|auth)"),
    ("storage", r"(ì €ì¥ê³µê°„|storage|sd\s?card|ê¶Œí•œ\s?ê±°ë¶€)"),
    ("input_lag", r"(ì…ë ¥\s?ì§€ì—°|í„°ì¹˜\s?ì§€ì—°|ui\s?ì§€ì—°|input\s?lag)"),
    ("crash", r"(í¬ë˜ì‹œ|crash|ê°•ì œì¢…ë£Œ|í”„ë¡œì„¸ìŠ¤\s?ì¢…ë£Œ)"),
    ("freeze", r"(ë©ˆì¶¤|ë²„ë²…ì„|í”„ë¦¬ì¦ˆ|freeze)"),
    ("network", r"(ë„¤íŠ¸ì›Œí¬|network|í•‘|ping|latency|disconnect)"),
    ("render", r"(ë Œë”ë§|render|ê·¸ë¦¼ì|í…ìŠ¤ì²˜|texture|shader)"),
    ("ui_scaling", r"(ì‘ê²Œ\s?ë³´ì„|ì¶•ì†Œ|ç¼©å°|small ui|ìŠ¤ì¼€ì¼ë§|scaling|í•´ìƒë„\s?ê³ ì •|1080p)"),
    ("ui_margin", r"(ì¢Œì¸¡\s?ì—¬ë°±|ì—¬ë°±\s?ë°œìƒ|margin|padding)"),
    ("option_graphics", r"(ê·¸ë˜í”½\s?ì˜µì…˜|ì˜µì…˜\s?í™”ë©´|settings|option)"),
    ("frame_cap", r"(í”„ë ˆì„\s?ì„¤ì •|fps\s?ì œí•œ|60fps|120fps)"),
    ("audio", r"(ì†Œë¦¬|ì˜¤ë””ì˜¤|audio|ë¬´ìŒ|ë³¼ë¥¨)"),
    ("camera", r"(ì¹´ë©”ë¼|camera)"),
    ("thermal", r"(ì¨ë©€|ë°œì—´|thermal|throttl)"),
    ("fps", r"(í”„ë ˆì„|fps)"),
]

def tag_issue_comment(comment: str) -> list:
    s = _jamo_norm(comment)
    tags = []
    for tag, pat in ISSUE_TAG_PATTERNS:
        if re.search(pat, s, re.I):
            tags.append(tag)
    return list(dict.fromkeys(tags))

# comment_text / issue_tags ìƒì„±
if "comment_text" not in df_final.columns:
    if "comment_cell" in df_final.columns:
        df_final["comment_text"] = df_final["comment_cell"].fillna("").astype(str)
    else:
        df_final["comment_text"] = ""

def _strip_excel_thread_prefix(s: str) -> str:
    if s is None:
        return ""
    text = str(s)
    m = re.search(r"ëŒ“ê¸€\s*:\s*", text)
    if m:
        return text[m.end():].strip()
    return text.strip()

df_final["comment_text"] = df_final["comment_text"].astype(str).apply(_strip_excel_thread_prefix)

df_final["comment_norm"] = (
    df_final["comment_text"]
    .fillna("")
    .astype(str)
    .apply(_jamo_norm)
)
df_final["issue_tags"] = (
    df_final["comment_text"]
    .fillna("")
    .astype(str)
    .apply(tag_issue_comment)
)

for col in ["Device(Model)", "GPU", "Chipset", "OS"]:
    if col not in df_final.columns:
        df_final[col] = ""

# ìŠ¤í™ ë³‘í•© + ì½”ë©˜íŠ¸/íƒœê¹…ì´ ë°˜ì˜ëœ ìµœì¢… Fail ë·°ë§Œ ì¶œë ¥
# issue_tagsë¥¼ ë§ˆì§€ë§‰ ì»¬ëŸ¼ìœ¼ë¡œ í•¨ê»˜ ë…¸ì¶œ
cols_show = [
    c for c in [
        "Sheet","Device(Model)","GPU","Chipset","RAM","OS","Resolution","Rank","Checklist","comment_text","issue_tags"
    ] if c in df_final.columns
]
st.write("### í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ì—ì„œ Fail + ì½”ë©˜íŠ¸ + ìŠ¤í™ (ìµœì¢…)")
st.dataframe(df_final[cols_show])

# ==============================
# 7-1) ìŠ¤í™ ë³‘í•© ìš”ì•½ UI
# ==============================
with step_status("ìŠ¤í™ ë³‘í•© ìš”ì•½"):
    if spec_match_info is not None:
        st.success(
            f"ìŠ¤í™ ë§¤ì¹­ ê²°ê³¼: GPU ì±„ì›€ {spec_match_info['matched']} / "
            f"{spec_match_info['total']} ê±´ ({spec_match_info['match_rate']}%)"
        )
        if not df_spec_mismatch_sample.empty:
            diag_dump(
                "ìŠ¤í™ ë³‘í•© ë¯¸ë§¤ì¹­ ìƒ˜í”Œ(ìƒìœ„ 20)",
                df_spec_mismatch_sample,
            )
    else:
        st.info("ìŠ¤í™ ì‹œíŠ¸ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë§¤ì¹­ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ==============================
# 7-2) ì½”ë©˜íŠ¸ ì •ê·œí™” / íƒœê¹… ìƒíƒœ UI
# ==============================
with step_status("ì½”ë©˜íŠ¸ ì •ê·œí™” / íƒœê¹…"):
    st.write("comment_text / issue_tags ì •ê·œí™” ë° íƒœê¹…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# ==============================
# 8) êµ°ì§‘ ì‚°ì¶œ
# ==============================
with step_status("êµ°ì§‘(Cluster) í†µê³„ ì‚°ì¶œ"):
    if "Chipset" not in df_final.columns and "CPU" in df_final.columns:
        df_final["Chipset"] = df_final["CPU"]

    if "GPU" not in df_final.columns:
        df_final["GPU"] = ""

    # ë””ë²„ê·¸ìš© í´ëŸ¬ìŠ¤í„° í†µê³„ (ì›¹ì—ì„œ í™•ì¸ ê°€ëŠ¥)
    try:
        # ----------------------------
        # 1) ì´ìŠˆ Ã— GPU Ã— Chipset Ã— í•´ìƒë„ êµ°ì§‘(issue_hw)
        # ----------------------------
        needed = {"issue_tags", "GPU", "Chipset", "Resolution", "Device(Model)"}
        if needed.issubset(df_final.columns):
            tmp = df_final.copy()
            tmp["GPU"] = tmp["GPU"].fillna("").astype(str).str.strip()
            tmp["Chipset"] = tmp["Chipset"].fillna("").astype(str).str.strip()
            tmp["Resolution"] = tmp["Resolution"].fillna("").astype(str).str.strip()

            # ìŠ¤í™ ì •ë³´ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ì œì™¸
            tmp = tmp[
                (tmp["GPU"] != "")
                & (tmp["Chipset"] != "")
                & (tmp["Resolution"] != "")
            ]

            if not tmp.empty and "issue_tags" in tmp.columns:
                ex = tmp.explode("issue_tags")
                ex["issue_tags"] = ex["issue_tags"].fillna("").astype(str).str.strip()
                ex = ex[ex["issue_tags"] != ""]

                if not ex.empty:
                    df_issue_hw = (
                        ex.groupby(["issue_tags", "GPU", "Chipset", "Resolution"])[
                            "Device(Model)"
                        ]
                        .agg(
                            fail_device_count=lambda s: s.dropna().nunique(),
                            repr_models=lambda s: ", ".join(
                                sorted(set(map(str, s.dropna())))[:5]
                            ),
                        )
                        .reset_index()
                        .sort_values(
                            "fail_device_count", ascending=False
                        )
                    )
                    diag_dump(
                        "ì´ìŠˆ Ã— GPU Ã— Chipset Ã— í•´ìƒë„ êµ°ì§‘(issue_hw)",
                        df_issue_hw,
                    )

        # ----------------------------
        # 2) ë‹¨ì¼ ì¶• ê¸°ì¤€ í†µê³„ + issue_tag Ã— ì¶• ë³„ ì§‘ê³„
        #    - GPU / Chipset / Resolution ê°ê°ì— ëŒ€í•´
        # ----------------------------
        cols = set(df_final.columns)

        # (a) GPU ê¸°ì¤€
        if {"GPU", "Device(Model)"}.issubset(cols):
            df_gpu = df_final.assign(GPU=df_final["GPU"].fillna("").astype(str).str.strip())
            df_gpu = df_gpu[df_gpu["GPU"] != ""]

            # GPU ë‹¨ë… í†µê³„
            df_cluster_gpu = (
                df_gpu.groupby("GPU")["Device(Model)"]
                .nunique()
                .reset_index(name="fail_device_count")
                .sort_values("fail_device_count", ascending=False)
            )
            if not df_cluster_gpu.empty:
                diag_dump("í´ëŸ¬ìŠ¤í„° í†µê³„ - GPUë³„ Fail ë‹¨ë§ ìˆ˜", df_cluster_gpu)

            # issue_tag Ã— GPU ì§‘ê³„
            if "issue_tags" in df_gpu.columns:
                ex = df_gpu.explode("issue_tags")
                ex["issue_tags"] = ex["issue_tags"].fillna("").astype(str).str.strip()
                ex = ex[ex["issue_tags"] != ""]
                if not ex.empty:
                    df_by_gpu = (
                        ex.groupby(["issue_tags", "GPU"])["Device(Model)"]
                        .nunique()
                        .reset_index(name="fail_device_count")
                        .sort_values("fail_device_count", ascending=False)
                    )
                    diag_dump("ì´ìŠˆÃ—GPU ì§‘ê³„(by_gpu_cluster)", df_by_gpu)

        # (b) Chipset(CPU) ê¸°ì¤€
        if {"Chipset", "Device(Model)"}.issubset(cols):
            df_chip = df_final.assign(Chipset=df_final["Chipset"].fillna("").astype(str).str.strip())
            df_chip = df_chip[df_chip["Chipset"] != ""]

            df_cluster_chip = (
                df_chip.groupby("Chipset")["Device(Model)"]
                .nunique()
                .reset_index(name="fail_device_count")
                .sort_values("fail_device_count", ascending=False)
            )
            if not df_cluster_chip.empty:
                diag_dump("í´ëŸ¬ìŠ¤í„° í†µê³„ - Chipsetë³„ Fail ë‹¨ë§ ìˆ˜", df_cluster_chip)

            if "issue_tags" in df_chip.columns:
                ex = df_chip.explode("issue_tags")
                ex["issue_tags"] = ex["issue_tags"].fillna("").astype(str).str.strip()
                ex = ex[ex["issue_tags"] != ""]
                if not ex.empty:
                    df_by_chip = (
                        ex.groupby(["issue_tags", "Chipset"])["Device(Model)"]
                        .nunique()
                        .reset_index(name="fail_device_count")
                        .sort_values("fail_device_count", ascending=False)
                    )
                    diag_dump("ì´ìŠˆÃ—Chipset ì§‘ê³„(by_chipset_cluster)", df_by_chip)

        # (c) í•´ìƒë„ ê¸°ì¤€
        if {"Resolution", "Device(Model)"}.issubset(cols):
            df_res = df_final.assign(
                Resolution=df_final["Resolution"].fillna("").astype(str).str.strip()
            )
            df_res = df_res[df_res["Resolution"] != ""]

            df_cluster_res = (
                df_res.groupby("Resolution")["Device(Model)"]
                .nunique()
                .reset_index(name="fail_device_count")
                .sort_values("fail_device_count", ascending=False)
            )
            if not df_cluster_res.empty:
                diag_dump("í´ëŸ¬ìŠ¤í„° í†µê³„ - í•´ìƒë„ë³„ Fail ë‹¨ë§ ìˆ˜", df_cluster_res)

            if "issue_tags" in df_res.columns:
                ex = df_res.explode("issue_tags")
                ex["issue_tags"] = ex["issue_tags"].fillna("").astype(str).str.strip()
                ex = ex[ex["issue_tags"] != ""]
                if not ex.empty:
                    df_by_res = (
                        ex.groupby(["issue_tags", "Resolution"])["Device(Model)"]
                        .nunique()
                        .reset_index(name="fail_device_count")
                        .sort_values("fail_device_count", ascending=False)
                    )
                    diag_dump("ì´ìŠˆÃ—í•´ìƒë„ ì§‘ê³„(by_resolution_cluster)", df_by_res)
    except Exception as e:
        diag_dump("í´ëŸ¬ìŠ¤í„° í†µê³„ ê³„ì‚° ì˜¤ë¥˜", str(e))

# ==============================
# 9) ë©”íŠ¸ë¦­ ê³„ì‚° (ë‚´ë¶€ ê³„ì‚°ë§Œ ìˆ˜í–‰, ì›¹ ì¶œë ¥ ì—†ìŒ)
# ==============================
metrics = {}

total_rows = len(df_final)
metrics["total_rows"] = total_rows
metrics["total_fail_issues"] = total_rows

if "issue_tags" in df_final.columns:
    exploded = df_final.explode("issue_tags")
    vc = exploded["issue_tags"].value_counts().reset_index(name="count")
    vc = vc.rename(columns={"issue_tags": "value"})
    tag_counts = vc.to_dict(orient="records")
else:
    tag_counts = []
metrics["by_issue_tag"] = tag_counts

# ì´ìŠˆ Ã— GPU Ã— Chipset Ã— í•´ìƒë„ êµ°ì§‘(issue_hw) â€“ ë©”íŠ¸ë¦­ìš©
clusters_issue_hw = []
needed_cols = {"issue_tags", "GPU", "Chipset", "Resolution", "Device(Model)"}
if needed_cols.issubset(df_final.columns):
    tmp = df_final.copy()
    tmp["GPU"] = tmp["GPU"].fillna("").astype(str).str.strip()
    tmp["Chipset"] = tmp["Chipset"].fillna("").astype(str).str.strip()
    tmp["Resolution"] = tmp["Resolution"].fillna("").astype(str).str.strip()

    tmp = tmp[
        (tmp["GPU"] != "")
        & (tmp["Chipset"] != "")
        & (tmp["Resolution"] != "")
    ]

    if not tmp.empty:
        ex = tmp.explode("issue_tags")
        ex["issue_tags"] = ex["issue_tags"].fillna("").astype(str).str.strip()
        ex = ex[ex["issue_tags"] != ""]

        if not ex.empty:
            grp = (
                ex.groupby(["issue_tags", "GPU", "Chipset", "Resolution"])[
                    "Device(Model)"
                ]
                .agg(lambda s: sorted(set(map(str, s.dropna()))))
                .reset_index()
            )

            for _, r in grp.iterrows():
                models = r["Device(Model)"]
                count = len(models)
                clusters_issue_hw.append(
                    {
                        "feature_tag": r["issue_tags"],
                        "hw_type": "gpu+chipset",
                        "hw_value": f"{r['GPU']} / {r['Chipset']}",
                        "resolution_group": r["Resolution"],
                        "count": count,
                        "repr_models": models[:5],
                    }
                )

metrics["clusters"] = {"issue_hw": clusters_issue_hw}
metrics["clusters_feature_detailed"] = []

meta = {
    "build_version": "KP 4.2.0",
    "scope": "Android / iOS í˜¸í™˜ì„± ê²€ì¦",
    "metrics": metrics,
}

# ==============================
# 10) LLM í˜¸ì¶œ (gpt-5.1, JSON ê°ì²´ ê°•ì œ)
# ==============================
sp = build_system_prompt()
up = build_user_prompt(df_final, meta)

st.write("### ğŸ¤– OpenAI í˜¸ì¶œ (í•„ìš” ì‹œ ëª¨ë¸ë§Œ êµì²´: gpt-5.1)")
with st.spinner("GPTê°€ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
    max_retries, wait = 3, 20
    result, last_error = None, None
    for attempt in range(max_retries):
        try:
            resp = client.chat.completions.create(
                model="gpt-5.1",          # í’ˆì§ˆ ìš°ì„ 
                temperature=0.1,
                top_p=0.9,
                messages=[{"role":"system","content":sp},{"role":"user","content":up}],
            )
            raw = resp.choices[0].message.content
            result = parse_llm_json(raw)
            result["meta"] = meta
            diag_dump("LLM ì›ë¬¸(ìš”ì•½)", raw[:3000])
            break
        except Exception as e:
            last_error = e
            if "429" in str(e) or "rate_limit_exceeded" in str(e).lower():
                if attempt < max_retries-1:
                    st.warning(f"429 ê°ì§€, ì¬ì‹œë„ {attempt+1}/{max_retries}")
                    time.sleep(wait); wait *= 2
                    continue
            st.error(f"OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            st.stop()
    if result is None:
        st.error(f"OpenAI ìµœì¢… ì‹¤íŒ¨: {last_error}")
        st.stop()

# ==============================
# 11) ë¦¬í¬íŠ¸ ìƒì„± (4ê°œ ì‹œíŠ¸)
# ==============================
# 11) ë¦¬í¬íŠ¸ ìƒì„±
try:
    # df_spec_allì´ ìŠ¤í™ ë³‘í•© ì‹œì ì— ë§Œë“¤ì–´ì ¸ ìˆë‹¤ë©´ ë‹¨ë§ ì „ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
    try:
        df_devices_all = df_spec_all.copy()
    except NameError:
        # ìŠ¤í™ ì‹œíŠ¸ê°€ ì—†ì„ ê²½ìš° ìµœì†Œí•œ df_final ê¸°ë°˜ìœ¼ë¡œë¼ë„ ìƒì„±
        df_devices_all = df_final.copy()

    # Platform ì»¬ëŸ¼ ë³´ì • (ì—†ìœ¼ë©´ AOSë¡œ ê¸°ë³¸ê°’)
    if "Platform" not in df_devices_all.columns:
        if "OS" in df_devices_all.columns:
            df_devices_all["Platform"] = df_devices_all["OS"].apply(
                lambda x: "iOS" if str(x).lower().startswith("ios") else "AOS"
            )
        else:
            df_devices_all["Platform"] = "AOS"

    # Device(Model) ì»¬ëŸ¼ ë³´ì •
    if "Device(Model)" not in df_devices_all.columns:
        for cand in ["Device", "device", "Model", "MODEL", "ë‹¨ë§ëª…", "ëª¨ë¸ëª…"]:
            if cand in df_devices_all.columns:
                df_devices_all["Device(Model)"] = df_devices_all[cand]
                break

    output_path = "QA_Report_4sheets.xlsx"

    write_excel_report(
        result=result,
        df_final=df_final,
        df_devices_all=df_devices_all,
        path=output_path,
    )

    st.success("âœ… 4ê°œ ì‹œíŠ¸ í¬í•¨ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
    with open(output_path, "rb") as f:
        st.download_button("ğŸ“Š Excel ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ", f.read(), file_name=output_path)
except Exception as e:
    st.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")

