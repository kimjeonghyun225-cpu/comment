# -*- coding: utf-8 -*-
# ìµœì¢… Streamlit ì•±: QA ê²°ê³¼ ìë™ ì½”ë©˜íŠ¸ ìƒì„±ê¸° (í—¤ë”ìë™íƒì§€/ë™ì˜ì–´ë§¤í•‘/ëª¨ë¸ì •ê·œí™” ì ìš©)

import os
import re
import io
import unicodedata
import pandas as pd
import openpyxl
import docx
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
from qa_patch_module import (
    find_test_sheet_candidates,
    enrich_with_column_comments,
    build_system_prompt, build_user_prompt,
    parse_llm_json, write_excel_report
)

# =========================
# í™˜ê²½ì„¤ì •
# =========================
load_dotenv()
# ìš°ì„ ìˆœìœ„: st.secrets > .env > os.environ
api_key = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY", ""))
if not api_key:
    st.error("OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. st.secrets ë˜ëŠ” .envì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=api_key)

st.set_page_config(page_title="QA ê²°ê³¼ ìë™ ì½”ë©˜íŠ¸ ìƒì„±ê¸°", layout="wide")
st.title(":bar_chart: QA ê²°ê³¼ ìë™ ì½”ë©˜íŠ¸ ìƒì„±ê¸°")

# =========================
# ê³µí†µ ìœ í‹¸
# =========================
def _norm(s: str) -> str:
    """ë¬¸ìì—´ ì •ê·œí™”: NFKC â†’ íŠ¹ìˆ˜ë¬¸ì ì œê±° â†’ ì†Œë¬¸ì/strip"""
    s = unicodedata.normalize("NFKC", str(s))
    s = re.sub(r"[\s\-\_/()\[\]{}:+Â·âˆ™â€¢]", "", s)
    return s.lower().strip()

def normalize_model_name_strict(s):
    """ëª¨ë¸ëª… ì •ê·œí™”: ê´„í˜¸/ìš©ëŸ‰/ìƒ‰ìƒ/êµ¬ë¶„ì ì œê±° í›„ ì†Œë¬¸ì/ë¬´ê³µë°±."""
    if pd.isna(s):
        return ""
    s = str(s)
    s = re.sub(r"\(.*?\)", "", s)  # ê´„í˜¸ ë‚´ìš© ì œê±°
    s = re.sub(r"\b(64|128|256|512)\s*gb\b", "", s, flags=re.I)  # ìš©ëŸ‰ ì œê±°
    s = re.sub(r"\b(black|white|blue|red|green|gold|silver|ê³¨ë“œ|ë¸”ë™|í™”ì´íŠ¸|ì‹¤ë²„)\b", "", s, flags=re.I)  # ìƒ‰ìƒ ì œê±°(í™•ì¥ ê°€ëŠ¥)
    s = re.sub(r"[\s\-_]+", "", s)  # ê³µë°±/í•˜ì´í”ˆ/ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
    return s.lower().strip()

# =========================
# ë¶„ì„ ì‹œíŠ¸: í—¤ë” íƒìƒ‰ ë° Fail+ì½”ë©˜íŠ¸ ì¶”ì¶œ
# =========================
def find_row_by_labels(ws, labels, search_rows=30, search_cols=70):
    """
    ë¶„ì„ ì‹œíŠ¸ ìƒë‹¨ì—ì„œ ì£¼ì–´ì§„ ë¼ë²¨(ë³µìˆ˜) ì¤‘ í•˜ë‚˜ê°€ ë“±ì¥í•˜ëŠ” 'í–‰ ë²ˆí˜¸'ë¥¼ ë°˜í™˜.
    ë™ì¼ ì»¬ëŸ¼ cì—ì„œ ì¥ë¹„ ìŠ¤í™ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•¨.
    """
    max_r = min(search_rows, ws.max_row)
    max_c = min(search_cols, ws.max_column)
    target = set(str(x).strip() for x in labels)
    for r in range(1, max_r + 1):
        for c in range(1, max_c + 1):
            v = ws.cell(row=r, column=c).value
            if v and str(v).strip() in target:
                return r
    return 0

def get_checklist_label(ws, row):
    """
    Fail ì…€ì˜ í–‰(row) ê¸°ì¤€, ìƒë‹¨ìœ¼ë¡œ ì˜¬ë¼ê°€ë©° ì§€ì •ëœ ì»¬ëŸ¼ë“¤ì—ì„œ í•­ëª© ë¼ë²¨ì„ êµ¬ì„±.
    ì‹œíŠ¸ë§ˆë‹¤ ë‹¤ë‹¨ í—¤ë”/ì¤‘ê°„ ì œëª©/ë³‘í•© êµ¬ì¡°ë¥¼ ê²¬ë”œ ìˆ˜ ìˆê²Œ ì„¤ê³„.
    """
    label_parts, columns_to_check = [], [6, 7, 9]  # í•„ìš” ì‹œ ì¡°ì •
    for c in columns_to_check:
        for r_search in range(row, 0, -1):
            cell_value = ws.cell(row=r_search, column=c).value
            if cell_value and str(cell_value).strip():
                label_parts.append(str(cell_value).replace("\n", " ").strip())
                break
    return " / ".join(label_parts)

def extract_comments_as_dataframe(wb, target_sheet_names):
    """
    ë¶„ì„ ì‹œíŠ¸ë“¤ì—ì„œ 'fail'ê°’ + ì½”ë©˜íŠ¸ê°€ ì¡´ì¬í•˜ëŠ” ì…€ë§Œ ì¶”ì¶œí•˜ì—¬ DFë¡œ ë°˜í™˜.
    ì»¬ëŸ¼: Sheet, Device(Model), Chipset, RAM, Rank, OS, Checklist, Comment(Text)
    """
    extracted = []
    for sheet_name in target_sheet_names:
        if sheet_name not in wb.sheetnames:
            st.warning(f"'{sheet_name}' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue

        ws = wb[sheet_name]
        header_rows = {
            "Model":   find_row_by_labels(ws, ["Model", "ì œí’ˆëª…"]),
            "Chipset": find_row_by_labels(ws, ["Chipset", "CPU", "AP"]),
            "RAM":     find_row_by_labels(ws, ["RAM", "ë©”ëª¨ë¦¬"]),
            "Rank":    find_row_by_labels(ws, ["Rating Grade?", "Rank", "ë“±ê¸‰"]),
            "OS":      find_row_by_labels(ws, ["OS Version", "Android", "iOS", "OS"]),
        }

        for row in ws.iter_rows():
            for cell in row:
                val = cell.value
                if isinstance(val, str) and val.strip().lower() == "fail" and cell.comment:
                    r, c = cell.row, cell.column
                    device_info = {
                        key: ws.cell(row=num, column=c).value if num > 0 else ""
                        for key, num in header_rows.items()
                    }
                    checklist = get_checklist_label(ws, r)
                    # MS ë§í¬ ê¼¬ë¦¬í‘œ ì œê±°
                    comment_text = (cell.comment.text or "").split(
                        "https://go.microsoft.com/fwlink/?linkid=870924.", 1
                    )[-1].strip()

                    extracted.append({
                        "Sheet": ws.title,
                        "Device(Model)": device_info.get("Model", ""),
                        "Chipset": device_info.get("Chipset", ""),
                        "RAM": device_info.get("RAM", ""),
                        "Rank": device_info.get("Rank", ""),
                        "OS": device_info.get("OS", ""),
                        "Checklist": checklist,
                        "Comment(Text)": comment_text,
                    })

    if not extracted:
        return None
    return pd.DataFrame(extracted)

# =========================
# ìŠ¤í™ ì‹œíŠ¸: í—¤ë” ìë™íƒì§€/ì»¬ëŸ¼ ì •ê·œí™”/ë™ì˜ì–´ ë§¤í•‘
# =========================
def find_header_row_for_spec(xls, sheet_name, max_scan_rows=12):
    """
    ìŠ¤í™ ì‹œíŠ¸ ìƒë‹¨ Ní–‰ì„ í›‘ì–´ Model/ì œí’ˆëª…/ëª¨ë¸ëª…/ì œí’ˆ/Device ë“± íŒ¨í„´ì´ ë³´ì´ëŠ” í–‰ì„ í—¤ë”ë¡œ ê²°ì •.
    ì—†ìœ¼ë©´ 0(ì²« í–‰) ë°˜í™˜.
    """
    df_probe = pd.read_excel(xls, sheet_name=sheet_name, header=None, engine="openpyxl")
    header_row_idx = 0
    header_candidates = [r"^model$", r"^device$", r"^ì œí’ˆëª…$", r"^ì œí’ˆ$", r"^ëª¨ë¸ëª…$", r"^ëª¨ë¸$"]
    for r in range(min(max_scan_rows, len(df_probe))):
        row_vals = df_probe.iloc[r].astype(str).fillna("")
        norm_vals = [_norm(v) for v in row_vals]
        for v in norm_vals:
            if any(re.search(pat, v) for pat in header_candidates):
                return r
    return header_row_idx

def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì»¬ëŸ¼ëª…ì„ ì •ê·œí™”í•˜ê³  í•œê¸€/ì˜ë¬¸ ë™ì˜ì–´ë¥¼ í‘œì¤€ ì»¬ëŸ¼ìœ¼ë¡œ ë§¤í•‘.
    """
    original_cols = list(df.columns)
    norm_cols = [_norm(c) for c in original_cols]
    col_map = {}

    synonyms = {
        # ëª¨ë¸
        r"^(model|device|ì œí’ˆëª…|ì œí’ˆ|ëª¨ë¸ëª…|ëª¨ë¸)$": "Model",
        # ì œì¡°ì‚¬
        r"^(maker|manufacturer|brand|oem|ì œì¡°ì‚¬|ë²¤ë”)$": "ì œì¡°ì‚¬",
        # GPU
        r"^(gpu|ê·¸ë˜í”½|ê·¸ë˜í”½ì¹©|ê·¸ë˜í”½ìŠ¤|ê·¸ë˜í”½í”„ë¡œì„¸ì„œ)$": "GPU",
        # ì¹©ì…‹/CPU
        r"^(chipset|soc|ap|cpu)$": "Chipset",
        # RAM
        r"^(ram|ë©”ëª¨ë¦¬)$": "RAM",
        # OS
        r"^(os|osversion|android|ios|íŒì›¨ì–´|ì†Œí”„íŠ¸ì›¨ì–´ë²„ì „)$": "OS",
        # ë“±ê¸‰
        r"^(rank|rating|ratinggrade|ë“±ê¸‰)$": "Rank",
    }

    for norm_name, orig_name in zip(norm_cols, original_cols):
        mapped = None
        for pat, std_name in synonyms.items():
            if re.search(pat, norm_name):
                mapped = std_name
                break
        if mapped is None:
            mapped = orig_name
        col_map[orig_name] = mapped

    return df.rename(columns=col_map)

def detect_model_col(df: pd.DataFrame):
    if "Model" in df.columns:
        return "Model"
    for c in df.columns:
        n = _norm(c)
        if re.search(r"^(model|device|ì œí’ˆëª…|ì œí’ˆ|ëª¨ë¸ëª…|ëª¨ë¸)$", n):
            return c
    return None

def load_std_spec_df(xls, sheet):
    """
    ìŠ¤í™ ì‹œíŠ¸ë¥¼: í—¤ë”ìë™íƒì§€ â†’ í‘œì¤€ì»¬ëŸ¼ ë§¤í•‘ â†’ model_norm ìƒì„± â†’ ë³‘í•©ëŒ€ìƒ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
    """
    hdr = find_header_row_for_spec(xls, sheet)
    df = pd.read_excel(xls, sheet_name=sheet, header=hdr, engine="openpyxl")
    df = standardize_columns(df)
    model_col = detect_model_col(df)
    if model_col is None:
        raise ValueError(f"'{sheet}'ì—ì„œ ëª¨ë¸ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì»¬ëŸ¼: {list(df.columns)}")
    df["model_norm"] = df[model_col].apply(normalize_model_name_strict)

    cols_keep = ["model_norm"]
    for c in ["GPU", "ì œì¡°ì‚¬", "Chipset", "RAM", "OS", "Rank", "Model"]:
        if c in df.columns:
            cols_keep.append(c)
    return df[cols_keep]

# =========================
# í†µê³„/ìš”ì•½ ìœ í‹¸
# =========================
def top_group_counts(df, key, topn=5):
    if key not in df.columns:
        return "N/A"
    vc = df[key].fillna("N/A").astype(str).str.strip().value_counts().head(topn)
    return "; ".join([f"{k}: {v}ê±´" for k, v in vc.items()])

# =========================
# UI: íŒŒì¼ ì—…ë¡œë“œ
# =========================
uploaded_file = st.file_uploader("ì›ë³¸ QA ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["xlsx"])

if uploaded_file:
    # ì‹œíŠ¸ ìë™ ê°ì§€ìš© Excel ê°ì²´ ìƒì„±
    xls = pd.ExcelFile(uploaded_file, engine="openpyxl")

    # âœ… [íŒ¨ì¹˜ ëª¨ë“ˆ ì‚¬ìš©] í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ ìë™ í›„ë³´ ê°ì§€ + ì„ íƒ
    test_candidates = find_test_sheet_candidates(xls)
    st.subheader("1. í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ ì„ íƒ (AOS/iOS ê°ê° 1ê°œ ì´ìƒ ê¶Œì¥)")
    test_sheets_selected = st.multiselect(
        "í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (íŒ€ë§ˆë‹¤ ì‹œíŠ¸ëª…ì´ ë‹¬ë¼ë„ ìë™ ê°ì§€ë©ë‹ˆë‹¤)",
        options=test_candidates,
        default=test_candidates[:2]  # ìë™ í›„ë³´ ì¤‘ 2ê°œ ê¸°ë³¸ ì„ íƒ
    )

    if not test_sheets_selected:
        st.error("âŒ ìµœì†Œ 1ê°œ ì´ìƒì˜ í…ŒìŠ¤íŠ¸ ì‹œíŠ¸ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
        st.stop()

    # âœ… ê¸°ì¡´ ìŠ¤í™ ì‹œíŠ¸ ì„ íƒ ë¶€ë¶„ì€ ìœ ì§€ (ë‚´ë¶€ ë³‘í•©ìš©)
    sheet_names = xls.sheet_names
    default_spec = [s for s in ["AOS_Device_List", "iOS_Device_List"] if s in sheet_names]
    st.subheader("2. ìŠ¤í™ ì‹œíŠ¸ ì„ íƒ (AOS/iOS ë””ë°”ì´ìŠ¤ ë¦¬ìŠ¤íŠ¸)")
    spec_sheets_selected = st.multiselect(
        "GPU/ì œì¡°ì‚¬/Chipset/RAM/OS/Rank ë“± ì¶”ê°€ ì •ë³´ê°€ í¬í•¨ëœ ì‹œíŠ¸",
        options=sheet_names,
        default=default_spec
    )
    st.markdown("---")

    if st.button("ë¶„ì„ ë° ì½”ë©˜íŠ¸ ìƒì„± ì‹œì‘", type="primary"):
        # 1) ë¶„ì„(Fail+ì½”ë©˜íŠ¸ ì¶”ì¶œ)
        wb = openpyxl.load_workbook(uploaded_file, data_only=True)
        df_issue = extract_comments_as_dataframe(wb, test_sheets_selected)
        if df_issue is None or df_issue.empty:
            st.warning("Fail + ì½”ë©˜íŠ¸ê°€ í¬í•¨ëœ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

        # ë¹„ê³ /Notes/Comment ì—´ê¹Œì§€ ë³‘í•© (í‚¤ ì»¬ëŸ¼ì€ ì—¬ëŸ¬ë¶„ ì‹œíŠ¸ êµ¬ì¡°ì— ë§ì¶° ì¡°ì • ê°€ëŠ¥)
        df_issue = enrich_with_column_comments(
            xls, 
            test_sheets_selected[0], 
            df_issue, 
            key_cols=["Checklist", "Device(Model)"]
        )

        # 2) ìŠ¤í™ ë³‘í•© (ì„ íƒëœ ë‚´ë¶€ ìŠ¤í™ ì‹œíŠ¸)
        df_final = df_issue.copy()
        match_rate = 0.0
        if spec_sheets_selected:
            st.info(f"ì„ íƒëœ ìŠ¤í™ ì‹œíŠ¸ {spec_sheets_selected}ì˜ ì¶”ê°€ ì •ë³´ë¥¼ ë³‘í•©í•©ë‹ˆë‹¤.")
            try:
                spec_frames = [load_std_spec_df(xls, s) for s in spec_sheets_selected]
                df_spec_all = pd.concat(spec_frames, ignore_index=True)
                df_spec_all = df_spec_all.drop_duplicates(subset=["model_norm"], keep="first")

                df_final["model_norm"] = df_final["Device(Model)"].apply(normalize_model_name_strict)
                df_final = pd.merge(df_final, df_spec_all, on="model_norm", how="left")

                if "GPU" in df_final.columns:
                    matched = int(df_final["GPU"].notna().sum())
                    match_rate = round(matched / len(df_final) * 100, 1)
                    st.success(f"ìŠ¤í™ ë§¤ì¹­ ê²°ê³¼: {matched} / {len(df_final)} ê±´ ({match_rate}%)")
            except Exception as e:
                st.error(f"ìŠ¤í™ ë³‘í•© ì¤‘ ì˜¤ë¥˜: {e}")

        st.success(f"{len(df_final)}ê°œì˜ 'Fail' í•­ëª© ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ.")
        st.dataframe(df_final.head(15), use_container_width=True)

        # 3) ê°„ë‹¨ í†µê³„ â†’ metrics_summary (LLM ì…ë ¥ìš©)
        def vc_topn(series, n=5):
            return series.fillna("N/A").astype(str).str.strip().value_counts().head(n).to_dict()

        metrics_summary = {
            "fail_count": int(len(df_final)),
            "by_gpu": vc_topn(df_final["GPU"]) if "GPU" in df_final.columns else {},
            "by_chipset": vc_topn(df_final["Chipset"]) if "Chipset" in df_final.columns else {},
            "by_ram": vc_topn(df_final["RAM"]) if "RAM" in df_final.columns else {},
            "by_rank": vc_topn(df_final["Rank"]) if "Rank" in df_final.columns else {},
            "by_maker": vc_topn(df_final["ì œì¡°ì‚¬"]) if "ì œì¡°ì‚¬" in df_final.columns else {},
        }

        # 4) LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„± (JSON ê°•ì œ)
        system_prompt = build_system_prompt()
        user_prompt = build_user_prompt(metrics_summary, df_final)  # df_issueë„ ê°€ëŠ¥í•˜ë‚˜, ìŠ¤í™ ë³‘í•©ëœ df_final ê¶Œì¥

        # (ì„ íƒ) ì¶œë ¥ ì „ í˜•ì‹ ì‹œë®¬ë ˆì´ì…˜: ì‹¤ì œ LLM ì…ë ¥ ë¯¸ë¦¬ë³´ê¸°
        with st.expander("ğŸ“¤ LLM ì…ë ¥ í”„ë¦¬ë·° (ì¶œë ¥ ì „ ì‹œë®¬ë ˆì´ì…˜)"):
            st.code(user_prompt, language="json")

        # ============================================
        # 5) GPT í˜¸ì¶œ + JSON ê²°ê³¼ íŒŒì‹± + Excel ë¦¬í¬íŠ¸ ìƒì„±
        # ============================================
        with st.spinner("GPTê°€ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                resp = client.chat.completions.create(
                    model="gpt-4o",        # í•„ìš” ì‹œ gpt-4.1-mini ë“±ìœ¼ë¡œ ì¡°ì •
                    temperature=0.2,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                )

                # JSON ê²°ê³¼ íŒŒì‹±
                result_json = parse_llm_json(resp.choices[0].message.content)

                # Excel ë¦¬í¬íŠ¸ ìƒì„± (ìŠ¤í™ ë³‘í•©ë³¸ df_final ì‚¬ìš© ê¶Œì¥)
                output_path = "QA_Report.xlsx"
                write_excel_report(result_json, df_final, output_path)

                st.success(f"âœ… AI ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ë¦¬í¬íŠ¸ê°€ '{output_path}'ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                with open(output_path, "rb") as f:
                    st.download_button(
                        label="ğŸ“Š Excel ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
                        data=f.read(),
                        file_name=output_path,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    )

            except Exception as e:
                st.error(f"OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.stop()

        # 6) (ì„ íƒ) ë§¤ì¹­ ì‹¤íŒ¨ ìƒ˜í”Œ/ë””ë²„ê·¸ ê°€ì‹œí™”
        with st.expander("ë””ë²„ê·¸/ì ê²€ ì •ë³´"):
            st.write(f"ìŠ¤í™ ë§¤ì¹­ë¥ : {match_rate}%")
            if "GPU" in df_final.columns:
                unmatched = df_final[df_final["GPU"].isna()]
                if not unmatched.empty:
                    st.write("ìŠ¤í™ ë§¤ì¹­ ì‹¤íŒ¨ ì‚¬ë¡€(ìƒìœ„ 10ê°œ):")
                    st.dataframe(unmatched.head(10), use_container_width=True)
